{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from iit import generate_data, get_iit_distribution_dataset_both\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from model_classifier import TorchDeepNeuralEmbeddingClassifier\n",
    "from model_regression import TorchLinearEmbeddingRegression\n",
    "import model_classifier_iit\n",
    "from model_classifier_iit import TorchDeepNeuralClassifierIIT\n",
    "from model_regression_iit import TorchLinearEmbeddingRegressionIIT\n",
    "from torch_shallow_neural_classifier import TorchShallowNeuralClassifier\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import vsm\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = ['zero', 'one', 'two', 'three', 'four',\n",
    "       'five', 'six', 'seven', 'eight', 'nine']\n",
    "\n",
    "train_test_split = 0.9\n",
    "X_train, y_train, X_test, y_test = generate_data(vals, train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['four', 'nine', 'four'],\n",
       " ['nine', 'nine', 'zero'],\n",
       " ['six', 'one', 'one'],\n",
       " ['seven', 'three', 'four'],\n",
       " ['five', 'nine', 'three']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[52, 81, 12, 49, 60]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['eight', 'six', 'five'],\n",
       " ['six', 'nine', 'two'],\n",
       " ['two', 'one', 'zero'],\n",
       " ['nine', 'five', 'five'],\n",
       " ['two', 'five', 'five']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a feed-forward network using randomized embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = 163\n",
    "num_inputs = 3\n",
    "num_layers = 2\n",
    "embed_dim = 5\n",
    "\n",
    "mod = TorchDeepNeuralEmbeddingClassifier(vals, output_size, num_inputs,\n",
    "                            num_layers, embed_dim, None, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished epoch 1000 of 1000; error is 0.11316589266061783"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TorchDeepNeuralEmbeddingClassifier(\n",
       "\tbatch_size=1028,\n",
       "\tmax_iter=1000,\n",
       "\teta=0.001,\n",
       "\toptimizer_class=<class 'torch.optim.adam.Adam'>,\n",
       "\tl2_strength=0,\n",
       "\tgradient_accumulation_steps=1,\n",
       "\tmax_grad_norm=None,\n",
       "\tvalidation_fraction=0.1,\n",
       "\tearly_stopping=False,\n",
       "\tn_iter_no_change=10,\n",
       "\twarm_start=False,\n",
       "\ttol=1e-05,\n",
       "\thidden_dim=50,\n",
       "\thidden_activation=Tanh(),\n",
       "\tnum_layers=2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mod.model.state_dict(), './model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.67      1.00      0.80         2\n",
      "           8       0.67      0.50      0.57         4\n",
      "          10       0.67      0.67      0.67         3\n",
      "          12       0.50      1.00      0.67         2\n",
      "          13       1.00      1.00      1.00         1\n",
      "          14       1.00      1.00      1.00         1\n",
      "          15       0.67      1.00      0.80         2\n",
      "          16       1.00      0.67      0.80         3\n",
      "          18       1.00      1.00      1.00         2\n",
      "          20       1.00      1.00      1.00         2\n",
      "          21       1.00      1.00      1.00         2\n",
      "          22       1.00      1.00      1.00         1\n",
      "          24       1.00      1.00      1.00         1\n",
      "          27       1.00      1.00      1.00         2\n",
      "          28       1.00      1.00      1.00         2\n",
      "          30       1.00      1.00      1.00         2\n",
      "          32       1.00      1.00      1.00         1\n",
      "          33       1.00      1.00      1.00         1\n",
      "          35       1.00      1.00      1.00         1\n",
      "          36       1.00      1.00      1.00         3\n",
      "          39       1.00      1.00      1.00         2\n",
      "          40       1.00      1.00      1.00         2\n",
      "          42       1.00      1.00      1.00         3\n",
      "          45       1.00      1.00      1.00         2\n",
      "          48       1.00      1.00      1.00         2\n",
      "          50       1.00      1.00      1.00         2\n",
      "          54       1.00      1.00      1.00         2\n",
      "          55       1.00      1.00      1.00         2\n",
      "          56       1.00      1.00      1.00         2\n",
      "          60       1.00      1.00      1.00         4\n",
      "          64       1.00      1.00      1.00         1\n",
      "          66       1.00      1.00      1.00         2\n",
      "          70       1.00      1.00      1.00         2\n",
      "          72       1.00      1.00      1.00         1\n",
      "          75       1.00      1.00      1.00         1\n",
      "          77       1.00      1.00      1.00         2\n",
      "          80       1.00      1.00      1.00         2\n",
      "          81       1.00      1.00      1.00         1\n",
      "          84       1.00      1.00      1.00         1\n",
      "          88       1.00      1.00      1.00         2\n",
      "          90       1.00      0.67      0.80         3\n",
      "          91       1.00      1.00      1.00         1\n",
      "          96       0.50      1.00      0.67         1\n",
      "         105       1.00      1.00      1.00         1\n",
      "         108       1.00      0.50      0.67         2\n",
      "         112       1.00      1.00      1.00         1\n",
      "         117       1.00      1.00      1.00         1\n",
      "         128       1.00      1.00      1.00         1\n",
      "         135       1.00      1.00      1.00         1\n",
      "         162       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.89       100\n",
      "   macro avg       0.86      0.87      0.86       100\n",
      "weighted avg       0.89      0.89      0.88       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "preds = mod.predict(X_test)\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a feed-forward network using BERT embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_weights_name = 'bert-base-uncased'\n",
    "# Initialize a BERT tokenizer and BERT model based on\n",
    "# `bert_weights_name`:\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(bert_weights_name)\n",
    "bert_model = BertModel.from_pretrained(bert_weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_embed = vsm.create_subword_pooling_vsm(\n",
    "    vals, bert_tokenizer, bert_model, layer=1, pool_func=vsm.mean_pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zero</th>\n",
       "      <td>0.368413</td>\n",
       "      <td>0.714821</td>\n",
       "      <td>-0.532399</td>\n",
       "      <td>-0.153238</td>\n",
       "      <td>-0.184203</td>\n",
       "      <td>0.009934</td>\n",
       "      <td>0.028352</td>\n",
       "      <td>-0.162773</td>\n",
       "      <td>0.163669</td>\n",
       "      <td>-0.471809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.637450</td>\n",
       "      <td>-0.782000</td>\n",
       "      <td>0.181008</td>\n",
       "      <td>-1.160265</td>\n",
       "      <td>0.005396</td>\n",
       "      <td>-0.899586</td>\n",
       "      <td>0.350256</td>\n",
       "      <td>-0.099035</td>\n",
       "      <td>-0.274523</td>\n",
       "      <td>0.308869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>0.213226</td>\n",
       "      <td>0.484864</td>\n",
       "      <td>-0.032716</td>\n",
       "      <td>-0.026842</td>\n",
       "      <td>0.090642</td>\n",
       "      <td>-0.086201</td>\n",
       "      <td>0.195947</td>\n",
       "      <td>-0.169620</td>\n",
       "      <td>0.540456</td>\n",
       "      <td>-0.261407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455036</td>\n",
       "      <td>-0.426076</td>\n",
       "      <td>0.282586</td>\n",
       "      <td>-0.676856</td>\n",
       "      <td>-0.045337</td>\n",
       "      <td>-0.428130</td>\n",
       "      <td>0.227807</td>\n",
       "      <td>0.216206</td>\n",
       "      <td>0.112196</td>\n",
       "      <td>-0.128516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>-0.121083</td>\n",
       "      <td>0.161060</td>\n",
       "      <td>-0.549375</td>\n",
       "      <td>-0.472711</td>\n",
       "      <td>-0.146909</td>\n",
       "      <td>0.155344</td>\n",
       "      <td>-0.133190</td>\n",
       "      <td>-0.483241</td>\n",
       "      <td>0.173656</td>\n",
       "      <td>-0.328344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303860</td>\n",
       "      <td>0.224042</td>\n",
       "      <td>0.113168</td>\n",
       "      <td>-0.807975</td>\n",
       "      <td>-0.281597</td>\n",
       "      <td>-0.575383</td>\n",
       "      <td>0.138091</td>\n",
       "      <td>0.198803</td>\n",
       "      <td>-0.091571</td>\n",
       "      <td>-0.442494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three</th>\n",
       "      <td>0.104971</td>\n",
       "      <td>0.313852</td>\n",
       "      <td>-0.340210</td>\n",
       "      <td>-0.434407</td>\n",
       "      <td>-0.049186</td>\n",
       "      <td>0.154321</td>\n",
       "      <td>-0.099751</td>\n",
       "      <td>-0.506876</td>\n",
       "      <td>0.389955</td>\n",
       "      <td>-0.244507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379173</td>\n",
       "      <td>0.134788</td>\n",
       "      <td>0.233690</td>\n",
       "      <td>-0.651362</td>\n",
       "      <td>-0.219017</td>\n",
       "      <td>-0.658988</td>\n",
       "      <td>0.203868</td>\n",
       "      <td>0.215337</td>\n",
       "      <td>-0.093137</td>\n",
       "      <td>-0.477617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>four</th>\n",
       "      <td>0.039704</td>\n",
       "      <td>0.210273</td>\n",
       "      <td>-0.526674</td>\n",
       "      <td>-0.221241</td>\n",
       "      <td>-0.102211</td>\n",
       "      <td>0.203096</td>\n",
       "      <td>-0.147871</td>\n",
       "      <td>-0.331833</td>\n",
       "      <td>0.267574</td>\n",
       "      <td>-0.481170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240441</td>\n",
       "      <td>-0.040645</td>\n",
       "      <td>0.122894</td>\n",
       "      <td>-0.991067</td>\n",
       "      <td>0.013572</td>\n",
       "      <td>-0.848153</td>\n",
       "      <td>0.368776</td>\n",
       "      <td>0.249214</td>\n",
       "      <td>-0.265129</td>\n",
       "      <td>-0.095733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>five</th>\n",
       "      <td>-0.039133</td>\n",
       "      <td>0.148628</td>\n",
       "      <td>-0.443105</td>\n",
       "      <td>-0.602812</td>\n",
       "      <td>0.024338</td>\n",
       "      <td>-0.077868</td>\n",
       "      <td>-0.239623</td>\n",
       "      <td>-0.467639</td>\n",
       "      <td>0.117604</td>\n",
       "      <td>-0.661229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410685</td>\n",
       "      <td>-0.126665</td>\n",
       "      <td>0.254384</td>\n",
       "      <td>-0.834398</td>\n",
       "      <td>-0.037767</td>\n",
       "      <td>-0.695847</td>\n",
       "      <td>0.188720</td>\n",
       "      <td>0.237780</td>\n",
       "      <td>-0.017827</td>\n",
       "      <td>-0.366614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>six</th>\n",
       "      <td>0.304316</td>\n",
       "      <td>0.202454</td>\n",
       "      <td>-0.506930</td>\n",
       "      <td>-0.336193</td>\n",
       "      <td>0.042346</td>\n",
       "      <td>-0.201237</td>\n",
       "      <td>-0.326339</td>\n",
       "      <td>-0.235801</td>\n",
       "      <td>0.244673</td>\n",
       "      <td>-0.600611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417288</td>\n",
       "      <td>-0.329488</td>\n",
       "      <td>0.127992</td>\n",
       "      <td>-0.932242</td>\n",
       "      <td>-0.041394</td>\n",
       "      <td>-0.668947</td>\n",
       "      <td>-0.093982</td>\n",
       "      <td>0.385106</td>\n",
       "      <td>0.048364</td>\n",
       "      <td>-0.338787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seven</th>\n",
       "      <td>0.092242</td>\n",
       "      <td>0.176112</td>\n",
       "      <td>-0.475537</td>\n",
       "      <td>-0.412275</td>\n",
       "      <td>0.071916</td>\n",
       "      <td>-0.310987</td>\n",
       "      <td>-0.048490</td>\n",
       "      <td>-0.409864</td>\n",
       "      <td>0.006404</td>\n",
       "      <td>-0.807861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095583</td>\n",
       "      <td>-0.178779</td>\n",
       "      <td>0.421195</td>\n",
       "      <td>-0.693458</td>\n",
       "      <td>0.123755</td>\n",
       "      <td>-0.667253</td>\n",
       "      <td>0.076955</td>\n",
       "      <td>-0.138880</td>\n",
       "      <td>-0.079268</td>\n",
       "      <td>-0.244648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eight</th>\n",
       "      <td>-0.033224</td>\n",
       "      <td>0.192466</td>\n",
       "      <td>-0.507554</td>\n",
       "      <td>-0.419275</td>\n",
       "      <td>0.235861</td>\n",
       "      <td>0.105365</td>\n",
       "      <td>-0.255650</td>\n",
       "      <td>-0.200700</td>\n",
       "      <td>-0.053316</td>\n",
       "      <td>-0.733084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233600</td>\n",
       "      <td>-0.171980</td>\n",
       "      <td>0.286490</td>\n",
       "      <td>-0.620115</td>\n",
       "      <td>-0.104281</td>\n",
       "      <td>-0.584950</td>\n",
       "      <td>0.222393</td>\n",
       "      <td>0.159457</td>\n",
       "      <td>-0.355556</td>\n",
       "      <td>-0.570065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nine</th>\n",
       "      <td>0.105645</td>\n",
       "      <td>0.060501</td>\n",
       "      <td>-0.367164</td>\n",
       "      <td>-0.433360</td>\n",
       "      <td>0.425262</td>\n",
       "      <td>-0.032186</td>\n",
       "      <td>-0.136358</td>\n",
       "      <td>-0.358969</td>\n",
       "      <td>0.129830</td>\n",
       "      <td>-0.574778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081581</td>\n",
       "      <td>-0.280892</td>\n",
       "      <td>0.540993</td>\n",
       "      <td>-0.752147</td>\n",
       "      <td>-0.059858</td>\n",
       "      <td>-0.446215</td>\n",
       "      <td>0.033923</td>\n",
       "      <td>-0.036796</td>\n",
       "      <td>-0.296937</td>\n",
       "      <td>-0.314274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "zero   0.368413  0.714821 -0.532399 -0.153238 -0.184203  0.009934  0.028352   \n",
       "one    0.213226  0.484864 -0.032716 -0.026842  0.090642 -0.086201  0.195947   \n",
       "two   -0.121083  0.161060 -0.549375 -0.472711 -0.146909  0.155344 -0.133190   \n",
       "three  0.104971  0.313852 -0.340210 -0.434407 -0.049186  0.154321 -0.099751   \n",
       "four   0.039704  0.210273 -0.526674 -0.221241 -0.102211  0.203096 -0.147871   \n",
       "five  -0.039133  0.148628 -0.443105 -0.602812  0.024338 -0.077868 -0.239623   \n",
       "six    0.304316  0.202454 -0.506930 -0.336193  0.042346 -0.201237 -0.326339   \n",
       "seven  0.092242  0.176112 -0.475537 -0.412275  0.071916 -0.310987 -0.048490   \n",
       "eight -0.033224  0.192466 -0.507554 -0.419275  0.235861  0.105365 -0.255650   \n",
       "nine   0.105645  0.060501 -0.367164 -0.433360  0.425262 -0.032186 -0.136358   \n",
       "\n",
       "            7         8         9    ...       758       759       760  \\\n",
       "zero  -0.162773  0.163669 -0.471809  ...  0.637450 -0.782000  0.181008   \n",
       "one   -0.169620  0.540456 -0.261407  ...  0.455036 -0.426076  0.282586   \n",
       "two   -0.483241  0.173656 -0.328344  ...  0.303860  0.224042  0.113168   \n",
       "three -0.506876  0.389955 -0.244507  ...  0.379173  0.134788  0.233690   \n",
       "four  -0.331833  0.267574 -0.481170  ...  0.240441 -0.040645  0.122894   \n",
       "five  -0.467639  0.117604 -0.661229  ...  0.410685 -0.126665  0.254384   \n",
       "six   -0.235801  0.244673 -0.600611  ...  0.417288 -0.329488  0.127992   \n",
       "seven -0.409864  0.006404 -0.807861  ...  0.095583 -0.178779  0.421195   \n",
       "eight -0.200700 -0.053316 -0.733084  ...  0.233600 -0.171980  0.286490   \n",
       "nine  -0.358969  0.129830 -0.574778  ...  0.081581 -0.280892  0.540993   \n",
       "\n",
       "            761       762       763       764       765       766       767  \n",
       "zero  -1.160265  0.005396 -0.899586  0.350256 -0.099035 -0.274523  0.308869  \n",
       "one   -0.676856 -0.045337 -0.428130  0.227807  0.216206  0.112196 -0.128516  \n",
       "two   -0.807975 -0.281597 -0.575383  0.138091  0.198803 -0.091571 -0.442494  \n",
       "three -0.651362 -0.219017 -0.658988  0.203868  0.215337 -0.093137 -0.477617  \n",
       "four  -0.991067  0.013572 -0.848153  0.368776  0.249214 -0.265129 -0.095733  \n",
       "five  -0.834398 -0.037767 -0.695847  0.188720  0.237780 -0.017827 -0.366614  \n",
       "six   -0.932242 -0.041394 -0.668947 -0.093982  0.385106  0.048364 -0.338787  \n",
       "seven -0.693458  0.123755 -0.667253  0.076955 -0.138880 -0.079268 -0.244648  \n",
       "eight -0.620115 -0.104281 -0.584950  0.222393  0.159457 -0.355556 -0.570065  \n",
       "nine  -0.752147 -0.059858 -0.446215  0.033923 -0.036796 -0.296937 -0.314274  \n",
       "\n",
       "[10 rows x 768 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = 163\n",
    "num_inputs = 3\n",
    "num_layers = 2\n",
    "embed_dim = bert_embed.shape[1]\n",
    "freeze_embedding = True\n",
    "\n",
    "mod_bert_embed = TorchDeepNeuralClassifier(vals, output_size, num_inputs,\n",
    "                            num_layers, embed_dim, bert_embed,\n",
    "                            freeze_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished epoch 1000 of 1000; error is 0.04465832561254501"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TorchDeepNeuralClassifier(\n",
       "\tbatch_size=1028,\n",
       "\tmax_iter=1000,\n",
       "\teta=0.001,\n",
       "\toptimizer_class=<class 'torch.optim.adam.Adam'>,\n",
       "\tl2_strength=0,\n",
       "\tgradient_accumulation_steps=1,\n",
       "\tmax_grad_norm=None,\n",
       "\tvalidation_fraction=0.1,\n",
       "\tearly_stopping=False,\n",
       "\tn_iter_no_change=10,\n",
       "\twarm_start=False,\n",
       "\ttol=1e-05,\n",
       "\thidden_dim=50,\n",
       "\thidden_activation=Tanh(),\n",
       "\tnum_layers=2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_bert_embed.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.25      1.00      0.40         1\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       0.33      0.50      0.40         2\n",
      "           8       1.00      0.50      0.67         4\n",
      "          10       1.00      1.00      1.00         3\n",
      "          12       1.00      0.50      0.67         2\n",
      "          13       1.00      1.00      1.00         1\n",
      "          14       0.33      1.00      0.50         1\n",
      "          15       1.00      1.00      1.00         2\n",
      "          16       0.67      0.67      0.67         3\n",
      "          18       1.00      0.50      0.67         2\n",
      "          20       1.00      1.00      1.00         2\n",
      "          21       1.00      1.00      1.00         2\n",
      "          22       1.00      1.00      1.00         1\n",
      "          24       1.00      1.00      1.00         1\n",
      "          27       1.00      1.00      1.00         2\n",
      "          28       1.00      1.00      1.00         2\n",
      "          30       1.00      1.00      1.00         2\n",
      "          32       1.00      1.00      1.00         1\n",
      "          33       1.00      1.00      1.00         1\n",
      "          35       1.00      1.00      1.00         1\n",
      "          36       1.00      1.00      1.00         3\n",
      "          39       1.00      1.00      1.00         2\n",
      "          40       1.00      1.00      1.00         2\n",
      "          42       1.00      1.00      1.00         3\n",
      "          45       1.00      1.00      1.00         2\n",
      "          48       1.00      1.00      1.00         2\n",
      "          50       1.00      1.00      1.00         2\n",
      "          54       1.00      1.00      1.00         2\n",
      "          55       1.00      1.00      1.00         2\n",
      "          56       1.00      1.00      1.00         2\n",
      "          60       1.00      0.75      0.86         4\n",
      "          64       1.00      1.00      1.00         1\n",
      "          66       0.67      1.00      0.80         2\n",
      "          70       1.00      1.00      1.00         2\n",
      "          72       1.00      1.00      1.00         1\n",
      "          75       1.00      1.00      1.00         1\n",
      "          77       1.00      1.00      1.00         2\n",
      "          80       1.00      1.00      1.00         2\n",
      "          81       1.00      1.00      1.00         1\n",
      "          84       1.00      1.00      1.00         1\n",
      "          85       0.00      0.00      0.00         0\n",
      "          88       1.00      1.00      1.00         2\n",
      "          90       1.00      0.67      0.80         3\n",
      "          91       1.00      1.00      1.00         1\n",
      "          96       1.00      1.00      1.00         1\n",
      "         105       1.00      1.00      1.00         1\n",
      "         108       1.00      0.50      0.67         2\n",
      "         112       1.00      1.00      1.00         1\n",
      "         117       1.00      1.00      1.00         1\n",
      "         128       1.00      1.00      1.00         1\n",
      "         135       1.00      1.00      1.00         1\n",
      "         144       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.88       100\n",
      "   macro avg       0.88      0.87      0.86       100\n",
      "weighted avg       0.93      0.88      0.89       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "preds = mod_bert_embed.predict(X_test)\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a BERT model by tokenizing inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HfBertClassifierModel(nn.Module):\n",
    "    def __init__(self, n_classes, weights_name='bert-base-uncased'):\n",
    "        super().__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.weights_name = weights_name\n",
    "        self.bert = BertModel.from_pretrained(self.weights_name)\n",
    "        self.bert.train()\n",
    "        self.hidden_dim = self.bert.embeddings.word_embeddings.embedding_dim\n",
    "        # The only new parameters -- the classifier:\n",
    "        self.classifier_layer = nn.Linear(\n",
    "            self.hidden_dim, self.n_classes)\n",
    "\n",
    "    def forward(self, indices, mask):\n",
    "        reps = self.bert(\n",
    "            indices, attention_mask=mask)\n",
    "        return self.classifier_layer(reps.pooler_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HfBertClassifier(TorchShallowNeuralClassifier):\n",
    "    def __init__(self, weights_name, *args, **kwargs):\n",
    "        self.weights_name = weights_name\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(self.weights_name)\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.params += ['weights_name']\n",
    "\n",
    "    def build_graph(self):\n",
    "        return HfBertClassifierModel(self.n_classes_, self.weights_name)\n",
    "\n",
    "    def build_dataset(self, X, y=None):\n",
    "        data = self.tokenizer.batch_encode_plus(\n",
    "            X,\n",
    "            max_length=None,\n",
    "            add_special_tokens=True,\n",
    "            padding='longest',\n",
    "            return_attention_mask=True)\n",
    "        indices = torch.tensor(data['input_ids'])\n",
    "        mask = torch.tensor(data['attention_mask'])\n",
    "        if y is None:\n",
    "            dataset = torch.utils.data.TensorDataset(indices, mask)\n",
    "        else:\n",
    "            self.classes_ = sorted(set(y))\n",
    "            self.n_classes_ = len(self.classes_)\n",
    "            class2index = dict(zip(self.classes_, range(self.n_classes_)))\n",
    "            y = [class2index[label] for label in y]\n",
    "            y = torch.tensor(y)\n",
    "            dataset = torch.utils.data.TensorDataset(indices, mask, y)\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversion(X):\n",
    "    new_X = []\n",
    "    for inpts in X:\n",
    "        new_X.append(' '.join(inpts))\n",
    "    return new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_bert = HfBertClassifier('bert-base-uncased', max_iter=5, batch_size=8, n_iter_no_change=5, early_stopping=True, hidden_dim=100, eta=0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seven seven four',\n",
       " 'seven nine nine',\n",
       " 'four eight five',\n",
       " 'eight nine two',\n",
       " 'one five zero']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bert = conversion(X_train)\n",
    "X_test_bert = conversion(X_test)\n",
    "X_train_bert[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Finished epoch 5 of 5; error is 250.60060513019562"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HfBertClassifier(\n",
       "\tbatch_size=8,\n",
       "\tmax_iter=5,\n",
       "\teta=5e-05,\n",
       "\toptimizer_class=<class 'torch.optim.adam.Adam'>,\n",
       "\tl2_strength=0,\n",
       "\tgradient_accumulation_steps=1,\n",
       "\tmax_grad_norm=None,\n",
       "\tvalidation_fraction=0.1,\n",
       "\tearly_stopping=True,\n",
       "\tn_iter_no_change=5,\n",
       "\twarm_start=False,\n",
       "\ttol=1e-05,\n",
       "\thidden_dim=100,\n",
       "\thidden_activation=Tanh(),\n",
       "\tweights_name=bert-base-uncased)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_bert.fit(X_train_bert, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.93         8\n",
      "           1       0.00      0.00      0.00         1\n",
      "           4       0.50      0.50      0.50         2\n",
      "           6       0.50      1.00      0.67         1\n",
      "           8       0.00      0.00      0.00         5\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         2\n",
      "          12       0.50      0.20      0.29         5\n",
      "          15       0.00      0.00      0.00         1\n",
      "          17       0.00      0.00      0.00         2\n",
      "          18       0.07      1.00      0.13         1\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         3\n",
      "          24       0.25      0.60      0.35         5\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.00      0.00      0.00         2\n",
      "          28       0.00      0.00      0.00         4\n",
      "          30       0.00      0.00      0.00         6\n",
      "          32       0.00      0.00      0.00         2\n",
      "          36       0.29      1.00      0.44         2\n",
      "          40       0.50      1.00      0.67         3\n",
      "          42       1.00      0.50      0.67         4\n",
      "          44       0.00      0.00      0.00         2\n",
      "          45       0.00      0.00      0.00         1\n",
      "          48       0.00      0.00      0.00         3\n",
      "          49       0.00      0.00      0.00         0\n",
      "          51       0.00      0.00      0.00         1\n",
      "          54       0.00      0.00      0.00         1\n",
      "          55       0.00      0.00      0.00         2\n",
      "          56       0.00      0.00      0.00         3\n",
      "          60       0.00      0.00      0.00         2\n",
      "          63       0.33      1.00      0.50         1\n",
      "          64       0.00      0.00      0.00         1\n",
      "          70       0.00      0.00      0.00         1\n",
      "          72       0.56      0.83      0.67         6\n",
      "          77       0.00      0.00      0.00         1\n",
      "          78       0.00      0.00      0.00         1\n",
      "          81       0.00      0.00      0.00         2\n",
      "          84       0.00      0.00      0.00         2\n",
      "          90       0.20      1.00      0.33         1\n",
      "          91       0.00      0.00      0.00         0\n",
      "          96       1.00      1.00      1.00         1\n",
      "          98       0.00      0.00      0.00         2\n",
      "          99       0.00      0.00      0.00         1\n",
      "         112       0.00      0.00      0.00         3\n",
      "         126       0.00      0.00      0.00         0\n",
      "         135       0.00      0.00      0.00         1\n",
      "         144       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.29       100\n",
      "   macro avg       0.14      0.21      0.15       100\n",
      "weighted avg       0.24      0.29      0.24       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "preds = mod_bert.predict(X_test_bert)\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create IIT Dataset that computes xy and yz then xy + yz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "V1 = 1\n",
    "V2 = 2\n",
    "\n",
    "train_data_V1, test_data_V1 = get_iit_distribution_dataset_both(V1, vals)\n",
    "train_data_V2, test_data_V2 = get_iit_distribution_dataset_both(V2, vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_base_train_V1, y_base_train_V1, x_source_train_V1, y_source_train_V1 = train_data_V1\n",
    "x_base_test_V1, y_base_test_V1, x_source_test_V1, y_source_test_V1 = test_data_V1\n",
    "\n",
    "x_base_train_V2, y_base_train_V2, x_source_train_V2, y_source_train_V2 = train_data_V2\n",
    "x_base_test_V2, y_base_test_V2, x_source_test_V2, y_source_test_V2 = test_data_V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = len(x_base_train_V1)\n",
    "interventions_train_V1 = torch.zeros(train_size)\n",
    "interventions_train_V2 = torch.ones(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = len(x_base_test_V1)\n",
    "interventions_test_V1 = torch.zeros(test_size)\n",
    "interventions_test_V2 = torch.ones(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['seven', 'three', 'five'],\n",
       " ['four', 'seven', 'five'],\n",
       " ['three', 'nine', 'zero'],\n",
       " ['nine', 'five', 'zero'],\n",
       " ['two', 'seven', 'three']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_base_train_V1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_base_train_both = np.concatenate([np.array(x_base_train_V1),\n",
    "                                np.array(x_base_train_V2)], axis=0)\n",
    "\n",
    "X_sources_train_both = [np.concatenate([np.array(x_source_train_V1),\n",
    "                            np.array(x_source_train_V2)], axis=0)]\n",
    "\n",
    "y_base_train_both = np.concatenate([np.array(y_base_train_V1),\n",
    "                            np.array(y_base_train_V2)], axis=0)\n",
    "\n",
    "y_source_train_both = np.concatenate([np.array(y_source_train_V1),\n",
    "                            np.array(y_source_train_V2)])\n",
    "\n",
    "interventions_train_both = np.concatenate([np.array(interventions_train_V1),\n",
    "                            np.array(interventions_train_V2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_base_test_both = np.concatenate([np.array(x_base_test_V1),\n",
    "                                np.array(x_base_test_V2)], axis=0)\n",
    "\n",
    "X_sources_test_both = [np.concatenate([np.array(x_source_test_V1),\n",
    "                            np.array(x_source_test_V2)], axis=0)]\n",
    "\n",
    "y_base_test_both = np.concatenate([np.array(y_base_test_V1),\n",
    "                            np.array(y_base_test_V2)], axis=0)\n",
    "\n",
    "y_source_test_both = np.concatenate([np.array(y_source_test_V1),\n",
    "                            np.array(y_source_test_V2)])\n",
    "\n",
    "interventions_test_both = np.concatenate([np.array(interventions_test_V1),\n",
    "                            np.array(interventions_test_V2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "V1 = 0\n",
    "V2 = 1\n",
    "embedding_dim = 5\n",
    "max_iter = 2 \n",
    "\n",
    "id_to_coords = {\n",
    "    V1: [{\"layer\": 1, \"start\": 0, \"end\": embedding_dim}], \n",
    "    V2: [{\"layer\": 1, \"start\": embedding_dim, \"end\": embedding_dim*2}]    \n",
    "}\n",
    "\n",
    "both_model = TorchDeepNeuralClassifierIIT(\n",
    "    hidden_dim=embedding_dim*4, \n",
    "    hidden_activation=torch.nn.ReLU(), \n",
    "    num_layers=2, \n",
    "    id_to_coords=id_to_coords, \n",
    "    vocab=vals,\n",
    "    output_size=output_size,\n",
    "    num_inputs=num_inputs,\n",
    "    max_iter=max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished epoch 2 of 2; error is 19.970084190368652"
     ]
    }
   ],
   "source": [
    "_ = both_model.fit(\n",
    "    X_base_train_both, \n",
    "    X_sources_train_both, \n",
    "    y_base_train_both, \n",
    "    y_source_train_both, \n",
    "    interventions_train_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model_iit' from '/home/jamesflemings/Documents/work/CSLI/iit-distribution-rule/model_iit.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(model_iit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Evaluation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.50      0.32         8\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         5\n",
      "           9       0.00      0.00      0.00         3\n",
      "          10       0.00      0.00      0.00         2\n",
      "          12       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         3\n",
      "          15       0.00      0.00      0.00         2\n",
      "          18       0.00      0.00      0.00         4\n",
      "          20       0.00      0.00      0.00         2\n",
      "          22       0.00      0.00      0.00         2\n",
      "          24       0.00      0.00      0.00         4\n",
      "          25       0.00      0.00      0.00         1\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.00      0.00      0.00         1\n",
      "          28       0.00      0.00      0.00         2\n",
      "          30       0.00      0.00      0.00         5\n",
      "          32       0.00      0.00      0.00         2\n",
      "          33       0.00      0.00      0.00         1\n",
      "          35       0.00      0.00      0.00         3\n",
      "          36       0.00      0.00      0.00         1\n",
      "          39       0.00      0.00      0.00         2\n",
      "          40       0.00      0.00      0.00         2\n",
      "          42       0.00      0.00      0.00         2\n",
      "          43       0.00      0.00      0.00         0\n",
      "          45       0.00      0.00      0.00         3\n",
      "          48       0.00      0.00      0.00         2\n",
      "          51       0.00      0.00      0.00         1\n",
      "          52       0.00      0.00      0.00         1\n",
      "          54       0.00      0.00      0.00         3\n",
      "          56       0.00      0.00      0.00         3\n",
      "          57       0.00      0.00      0.00         0\n",
      "          60       0.00      0.00      0.00         1\n",
      "          63       0.00      0.00      0.00         2\n",
      "          64       0.00      0.00      0.00         1\n",
      "          66       0.00      0.00      0.00         3\n",
      "          70       0.00      0.00      0.00         2\n",
      "          72       0.00      0.00      0.00         4\n",
      "          75       0.00      0.00      0.00         0\n",
      "          77       0.00      0.00      0.00         1\n",
      "          78       0.00      0.00      0.00         0\n",
      "          88       0.00      0.00      0.00         1\n",
      "          90       0.00      0.00      0.00         1\n",
      "          91       0.00      0.00      0.00         3\n",
      "          96       0.00      0.00      0.00         2\n",
      "          99       0.00      0.00      0.00         1\n",
      "         112       0.00      0.00      0.00         1\n",
      "         117       0.00      0.00      0.00         1\n",
      "         121       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.04       100\n",
      "   macro avg       0.00      0.01      0.01       100\n",
      "weighted avg       0.02      0.04      0.03       100\n",
      "\n",
      "V1 counterfactual evaluation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.67      0.20         3\n",
      "           1       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         1\n",
      "           9       0.00      0.00      0.00         2\n",
      "          10       0.00      0.00      0.00         2\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         3\n",
      "          13       0.00      0.00      0.00         2\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       0.00      0.00      0.00         2\n",
      "          16       0.00      0.00      0.00         3\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       0.00      0.00      0.00         2\n",
      "          19       0.00      0.00      0.00         2\n",
      "          21       0.00      0.00      0.00         3\n",
      "          22       0.00      0.00      0.00         1\n",
      "          23       0.00      0.00      0.00         2\n",
      "          24       0.00      0.00      0.00         5\n",
      "          25       0.00      0.00      0.00         2\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.00      0.00      0.00         1\n",
      "          30       0.00      0.00      0.00         1\n",
      "          33       0.00      0.00      0.00         5\n",
      "          34       0.00      0.00      0.00         1\n",
      "          35       0.00      0.00      0.00         1\n",
      "          36       0.00      0.00      0.00         5\n",
      "          39       0.00      0.00      0.00         2\n",
      "          41       0.00      0.00      0.00         1\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         3\n",
      "          46       0.00      0.00      0.00         1\n",
      "          47       0.00      0.00      0.00         3\n",
      "          48       0.00      0.00      0.00         2\n",
      "          49       0.00      0.00      0.00         1\n",
      "          50       0.00      0.00      0.00         1\n",
      "          51       0.00      0.00      0.00         1\n",
      "          54       0.00      0.00      0.00         2\n",
      "          55       0.00      0.00      0.00         1\n",
      "          56       0.00      0.00      0.00         0\n",
      "          57       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00         3\n",
      "          60       0.00      0.00      0.00         2\n",
      "          62       0.00      0.00      0.00         0\n",
      "          63       0.00      0.00      0.00         3\n",
      "          65       0.00      0.00      0.00         1\n",
      "          67       0.00      0.00      0.00         1\n",
      "          68       0.00      0.00      0.00         1\n",
      "          69       0.00      0.00      0.00         1\n",
      "          70       0.00      0.00      0.00         1\n",
      "          72       0.00      0.00      0.00         1\n",
      "          73       0.00      0.00      0.00         2\n",
      "          74       0.00      0.00      0.00         0\n",
      "          81       0.00      0.00      0.00         1\n",
      "          83       0.00      0.00      0.00         1\n",
      "          84       0.00      0.00      0.00         1\n",
      "          86       0.00      0.00      0.00         1\n",
      "          87       0.00      0.00      0.00         1\n",
      "          88       0.00      0.00      0.00         1\n",
      "          91       0.00      0.00      0.00         1\n",
      "          98       0.00      0.00      0.00         0\n",
      "         135       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.02       100\n",
      "   macro avg       0.00      0.01      0.00       100\n",
      "weighted avg       0.00      0.02      0.01       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "IIT_preds_V1, base_preds_V1 = both_model.iit_predict(\n",
    "    x_base_test_V1, [x_source_test_V1], interventions_test_V1\n",
    ")\n",
    "\n",
    "print('Standard Evaluation')\n",
    "print(classification_report(y_base_test_V1, base_preds_V1))\n",
    "      \n",
    "print(\"V1 counterfactual evaluation\")\n",
    "print(classification_report(y_source_test_V1, IIT_preds_V1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IIT_preds_V2, base_preds_V2 = both_model.iit_predict(\n",
    "    x_base_test_V2, x_source_test_V2, interventions_test_V2\n",
    ")\n",
    "\n",
    "print(\"V2 counterfactual evaluation\")\n",
    "print(classification_report(y_source_test_V2, IIT_preds_V2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using regression instead of classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_regression = TorchLinearEmbeddingRegression(vocab=vals, num_inputs=3,\n",
    "                                                 num_layers=2, hidden_dim=50,\n",
    "                                                 embed_dim=5, max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished epoch 100 of 100; error is 2310.75634765625"
     ]
    }
   ],
   "source": [
    "_ = model_regression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6771984036272896"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_regression.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7395730106233249"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_regression.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.50014  , 27.05233  , 38.977577 , 14.095713 , -1.5937098,\n",
       "       30.873459 , 23.682442 , 57.35991  , 15.029133 , 18.85013  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_regression.predict(X_test)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 27, 40, 15, 0, 30, 24, 91, 15, 18]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_regression_model = TorchLinearEmbeddingRegressionIIT(\n",
    "    hidden_dim=embedding_dim*4, \n",
    "    hidden_activation=torch.nn.ReLU(), \n",
    "    num_layers=2, \n",
    "    id_to_coords=id_to_coords, \n",
    "    vocab=vals,\n",
    "    num_inputs=num_inputs,\n",
    "    max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished epoch 1000 of 1000; error is 2917.731445312575"
     ]
    }
   ],
   "source": [
    "_ = both_regression_model.fit(\n",
    "    X_base_train_both, \n",
    "    X_sources_train_both, \n",
    "    y_base_train_both, \n",
    "    y_source_train_both,\n",
    "    interventions_train_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22.6283, 12.8371, 20.6354, 29.3405, 14.1208], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score \n",
    "\n",
    "IIT_preds_V1, base_preds_V1 = both_regression_model.iit_predict(\n",
    "    x_base_test_V1, [x_source_test_V1], interventions_test_V1\n",
    ")\n",
    "#y_base_test_V1[:5]\n",
    "base_preds_V1.[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Evaluation\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/jamesflemings/Documents/work/CSLI/iit-distribution-rule/example_test.ipynb Cell 50'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jamesflemings/Documents/work/CSLI/iit-distribution-rule/example_test.ipynb#ch0000050?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mStandard Evaluation\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jamesflemings/Documents/work/CSLI/iit-distribution-rule/example_test.ipynb#ch0000050?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(r2_score(y_base_test_V1, base_preds_V1))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jamesflemings/Documents/work/CSLI/iit-distribution-rule/example_test.ipynb#ch0000050?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mV1 counterfactual evaluation\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jamesflemings/Documents/work/CSLI/iit-distribution-rule/example_test.ipynb#ch0000050?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(r2_score(y_source_test_V1, IIT_preds_V1))\n",
      "File \u001b[0;32m~/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_regression.py:789\u001b[0m, in \u001b[0;36mr2_score\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=701'>702</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mr2_score\u001b[39m(y_true, y_pred, \u001b[39m*\u001b[39m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, multioutput\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39muniform_average\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    <a href='file:///home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=702'>703</a>\u001b[0m     \u001b[39m\"\"\":math:`R^2` (coefficient of determination) regression score function.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=703'>704</a>\u001b[0m \n\u001b[1;32m    <a href='file:///home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=704'>705</a>\u001b[0m \u001b[39m    Best possible score is 1.0 and it can be negative (because the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=786'>787</a>\u001b[0m \u001b[39m    -3.0\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=787'>788</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=788'>789</a>\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[39m=\u001b[39m _check_reg_targets(\n\u001b[1;32m    <a href='file:///home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=789'>790</a>\u001b[0m         y_true, y_pred, multioutput\n\u001b[1;32m    <a href='file:///home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=790'>791</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=791'>792</a>\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    <a href='file:///home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=793'>794</a>\u001b[0m     \u001b[39mif\u001b[39;00m _num_samples(y_pred) \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_regression.py:96\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     <a href='file:///home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=93'>94</a>\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m     <a href='file:///home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=94'>95</a>\u001b[0m y_true \u001b[39m=\u001b[39m check_array(y_true, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m---> <a href='file:///home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=95'>96</a>\u001b[0m y_pred \u001b[39m=\u001b[39m check_array(y_pred, ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m     <a href='file:///home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=97'>98</a>\u001b[0m \u001b[39mif\u001b[39;00m y_true\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     <a href='file:///home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=98'>99</a>\u001b[0m     y_true \u001b[39m=\u001b[39m y_true\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/utils/validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/utils/validation.py?line=743'>744</a>\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    <a href='file:///home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/utils/validation.py?line=744'>745</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/utils/validation.py?line=745'>746</a>\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    <a href='file:///home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/utils/validation.py?line=746'>747</a>\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[1;32m    <a href='file:///home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/utils/validation.py?line=747'>748</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/utils/validation.py?line=748'>749</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    <a href='file:///home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/utils/validation.py?line=749'>750</a>\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/nlu/lib/python3.9/site-packages/torch/_tensor.py:678\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    <a href='file:///home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/torch/_tensor.py?line=675'>676</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m__array__, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    <a href='file:///home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/torch/_tensor.py?line=676'>677</a>\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/torch/_tensor.py?line=677'>678</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    <a href='file:///home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/torch/_tensor.py?line=678'>679</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/torch/_tensor.py?line=679'>680</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "print('Standard Evaluation')\n",
    "print(r2_score(y_base_test_V1, base_preds_V1.detach()))\n",
    "      \n",
    "print(\"V1 counterfactual evaluation\")\n",
    "print(r2_score(y_source_test_V1, IIT_preds_V1))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "23b0dade77de706664b673ec0b749cccbdb5cac5bb41527ce15ce25b9a737383"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('nlu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
