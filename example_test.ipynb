{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iit import generate_data\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from model import TorchDeepNeuralClassifier\n",
    "import numpy as np\n",
    "import torch\n",
    "import vsm\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = ['zero', 'one', 'two', 'three', 'four',\n",
    "       'five', 'six', 'seven', 'eight', 'nine']\n",
    "\n",
    "train_test_split = 0.9\n",
    "X_train, y_train, X_test, y_test = generate_data(vals, train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['four', 'nine', 'four'],\n",
       " ['nine', 'nine', 'zero'],\n",
       " ['six', 'one', 'one'],\n",
       " ['seven', 'three', 'four'],\n",
       " ['five', 'nine', 'three']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[52, 81, 12, 49, 60]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['eight', 'six', 'five'],\n",
       " ['six', 'nine', 'two'],\n",
       " ['two', 'one', 'zero'],\n",
       " ['nine', 'five', 'five'],\n",
       " ['two', 'five', 'five']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a feed-forward network using randomized embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = 163\n",
    "num_inputs = 3\n",
    "num_layers = 2\n",
    "embed_dim = 5\n",
    "\n",
    "mod = TorchDeepNeuralClassifier(vals, output_size, num_inputs,\n",
    "                            num_layers, embed_dim, None, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished epoch 1000 of 1000; error is 0.10345329344272614"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TorchDeepNeuralClassifier(\n",
       "\tbatch_size=1028,\n",
       "\tmax_iter=1000,\n",
       "\teta=0.001,\n",
       "\toptimizer_class=<class 'torch.optim.adam.Adam'>,\n",
       "\tl2_strength=0,\n",
       "\tgradient_accumulation_steps=1,\n",
       "\tmax_grad_norm=None,\n",
       "\tvalidation_fraction=0.1,\n",
       "\tearly_stopping=False,\n",
       "\tn_iter_no_change=10,\n",
       "\twarm_start=False,\n",
       "\ttol=1e-05,\n",
       "\thidden_dim=50,\n",
       "\thidden_activation=Tanh(),\n",
       "\tnum_layers=2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.67      1.00      0.80         2\n",
      "           8       0.67      0.50      0.57         4\n",
      "          10       0.67      0.67      0.67         3\n",
      "          12       0.50      1.00      0.67         2\n",
      "          13       1.00      1.00      1.00         1\n",
      "          14       1.00      1.00      1.00         1\n",
      "          15       0.67      1.00      0.80         2\n",
      "          16       1.00      0.67      0.80         3\n",
      "          18       1.00      1.00      1.00         2\n",
      "          20       1.00      1.00      1.00         2\n",
      "          21       1.00      1.00      1.00         2\n",
      "          22       1.00      1.00      1.00         1\n",
      "          24       1.00      1.00      1.00         1\n",
      "          27       1.00      1.00      1.00         2\n",
      "          28       1.00      1.00      1.00         2\n",
      "          30       1.00      1.00      1.00         2\n",
      "          32       1.00      1.00      1.00         1\n",
      "          33       1.00      1.00      1.00         1\n",
      "          35       1.00      1.00      1.00         1\n",
      "          36       1.00      1.00      1.00         3\n",
      "          39       1.00      1.00      1.00         2\n",
      "          40       1.00      1.00      1.00         2\n",
      "          42       1.00      1.00      1.00         3\n",
      "          45       1.00      1.00      1.00         2\n",
      "          48       1.00      1.00      1.00         2\n",
      "          50       1.00      1.00      1.00         2\n",
      "          54       1.00      1.00      1.00         2\n",
      "          55       1.00      1.00      1.00         2\n",
      "          56       1.00      1.00      1.00         2\n",
      "          60       1.00      1.00      1.00         4\n",
      "          64       1.00      1.00      1.00         1\n",
      "          66       1.00      1.00      1.00         2\n",
      "          70       1.00      1.00      1.00         2\n",
      "          72       1.00      1.00      1.00         1\n",
      "          75       1.00      1.00      1.00         1\n",
      "          77       1.00      1.00      1.00         2\n",
      "          80       1.00      1.00      1.00         2\n",
      "          81       1.00      1.00      1.00         1\n",
      "          84       1.00      1.00      1.00         1\n",
      "          88       1.00      1.00      1.00         2\n",
      "          90       1.00      0.67      0.80         3\n",
      "          91       1.00      1.00      1.00         1\n",
      "          96       0.50      1.00      0.67         1\n",
      "         105       1.00      1.00      1.00         1\n",
      "         108       1.00      0.50      0.67         2\n",
      "         112       1.00      1.00      1.00         1\n",
      "         117       1.00      1.00      1.00         1\n",
      "         128       1.00      1.00      1.00         1\n",
      "         135       1.00      1.00      1.00         1\n",
      "         162       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.89       100\n",
      "   macro avg       0.86      0.87      0.86       100\n",
      "weighted avg       0.89      0.89      0.88       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "preds = mod.predict(X_test)\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a feed-forward network using BERT embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_weights_name = 'bert-base-uncased'\n",
    "# Initialize a BERT tokenizer and BERT model based on\n",
    "# `bert_weights_name`:\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(bert_weights_name)\n",
    "bert_model = BertModel.from_pretrained(bert_weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_embed = vsm.create_subword_pooling_vsm(\n",
    "    vals, bert_tokenizer, bert_model, layer=1, pool_func=vsm.mean_pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zero</th>\n",
       "      <td>0.368413</td>\n",
       "      <td>0.714821</td>\n",
       "      <td>-0.532399</td>\n",
       "      <td>-0.153238</td>\n",
       "      <td>-0.184203</td>\n",
       "      <td>0.009934</td>\n",
       "      <td>0.028352</td>\n",
       "      <td>-0.162773</td>\n",
       "      <td>0.163669</td>\n",
       "      <td>-0.471809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.637450</td>\n",
       "      <td>-0.782000</td>\n",
       "      <td>0.181008</td>\n",
       "      <td>-1.160265</td>\n",
       "      <td>0.005396</td>\n",
       "      <td>-0.899586</td>\n",
       "      <td>0.350256</td>\n",
       "      <td>-0.099035</td>\n",
       "      <td>-0.274523</td>\n",
       "      <td>0.308869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>0.213226</td>\n",
       "      <td>0.484864</td>\n",
       "      <td>-0.032716</td>\n",
       "      <td>-0.026842</td>\n",
       "      <td>0.090642</td>\n",
       "      <td>-0.086201</td>\n",
       "      <td>0.195947</td>\n",
       "      <td>-0.169620</td>\n",
       "      <td>0.540456</td>\n",
       "      <td>-0.261407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455036</td>\n",
       "      <td>-0.426076</td>\n",
       "      <td>0.282586</td>\n",
       "      <td>-0.676856</td>\n",
       "      <td>-0.045337</td>\n",
       "      <td>-0.428130</td>\n",
       "      <td>0.227807</td>\n",
       "      <td>0.216206</td>\n",
       "      <td>0.112196</td>\n",
       "      <td>-0.128516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>-0.121083</td>\n",
       "      <td>0.161060</td>\n",
       "      <td>-0.549375</td>\n",
       "      <td>-0.472711</td>\n",
       "      <td>-0.146909</td>\n",
       "      <td>0.155344</td>\n",
       "      <td>-0.133190</td>\n",
       "      <td>-0.483241</td>\n",
       "      <td>0.173656</td>\n",
       "      <td>-0.328344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303860</td>\n",
       "      <td>0.224042</td>\n",
       "      <td>0.113168</td>\n",
       "      <td>-0.807975</td>\n",
       "      <td>-0.281597</td>\n",
       "      <td>-0.575383</td>\n",
       "      <td>0.138091</td>\n",
       "      <td>0.198803</td>\n",
       "      <td>-0.091571</td>\n",
       "      <td>-0.442494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three</th>\n",
       "      <td>0.104971</td>\n",
       "      <td>0.313852</td>\n",
       "      <td>-0.340210</td>\n",
       "      <td>-0.434407</td>\n",
       "      <td>-0.049186</td>\n",
       "      <td>0.154321</td>\n",
       "      <td>-0.099751</td>\n",
       "      <td>-0.506876</td>\n",
       "      <td>0.389955</td>\n",
       "      <td>-0.244507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379173</td>\n",
       "      <td>0.134788</td>\n",
       "      <td>0.233690</td>\n",
       "      <td>-0.651362</td>\n",
       "      <td>-0.219017</td>\n",
       "      <td>-0.658988</td>\n",
       "      <td>0.203868</td>\n",
       "      <td>0.215337</td>\n",
       "      <td>-0.093137</td>\n",
       "      <td>-0.477617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>four</th>\n",
       "      <td>0.039704</td>\n",
       "      <td>0.210273</td>\n",
       "      <td>-0.526674</td>\n",
       "      <td>-0.221241</td>\n",
       "      <td>-0.102211</td>\n",
       "      <td>0.203096</td>\n",
       "      <td>-0.147871</td>\n",
       "      <td>-0.331833</td>\n",
       "      <td>0.267574</td>\n",
       "      <td>-0.481170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.240441</td>\n",
       "      <td>-0.040645</td>\n",
       "      <td>0.122894</td>\n",
       "      <td>-0.991067</td>\n",
       "      <td>0.013572</td>\n",
       "      <td>-0.848153</td>\n",
       "      <td>0.368776</td>\n",
       "      <td>0.249214</td>\n",
       "      <td>-0.265129</td>\n",
       "      <td>-0.095733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>five</th>\n",
       "      <td>-0.039133</td>\n",
       "      <td>0.148628</td>\n",
       "      <td>-0.443105</td>\n",
       "      <td>-0.602812</td>\n",
       "      <td>0.024338</td>\n",
       "      <td>-0.077868</td>\n",
       "      <td>-0.239623</td>\n",
       "      <td>-0.467639</td>\n",
       "      <td>0.117604</td>\n",
       "      <td>-0.661229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410685</td>\n",
       "      <td>-0.126665</td>\n",
       "      <td>0.254384</td>\n",
       "      <td>-0.834398</td>\n",
       "      <td>-0.037767</td>\n",
       "      <td>-0.695847</td>\n",
       "      <td>0.188720</td>\n",
       "      <td>0.237780</td>\n",
       "      <td>-0.017827</td>\n",
       "      <td>-0.366614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>six</th>\n",
       "      <td>0.304316</td>\n",
       "      <td>0.202454</td>\n",
       "      <td>-0.506930</td>\n",
       "      <td>-0.336193</td>\n",
       "      <td>0.042346</td>\n",
       "      <td>-0.201237</td>\n",
       "      <td>-0.326339</td>\n",
       "      <td>-0.235801</td>\n",
       "      <td>0.244673</td>\n",
       "      <td>-0.600611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417288</td>\n",
       "      <td>-0.329488</td>\n",
       "      <td>0.127992</td>\n",
       "      <td>-0.932242</td>\n",
       "      <td>-0.041394</td>\n",
       "      <td>-0.668947</td>\n",
       "      <td>-0.093982</td>\n",
       "      <td>0.385106</td>\n",
       "      <td>0.048364</td>\n",
       "      <td>-0.338787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seven</th>\n",
       "      <td>0.092242</td>\n",
       "      <td>0.176112</td>\n",
       "      <td>-0.475537</td>\n",
       "      <td>-0.412275</td>\n",
       "      <td>0.071916</td>\n",
       "      <td>-0.310987</td>\n",
       "      <td>-0.048490</td>\n",
       "      <td>-0.409864</td>\n",
       "      <td>0.006404</td>\n",
       "      <td>-0.807861</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095583</td>\n",
       "      <td>-0.178779</td>\n",
       "      <td>0.421195</td>\n",
       "      <td>-0.693458</td>\n",
       "      <td>0.123755</td>\n",
       "      <td>-0.667253</td>\n",
       "      <td>0.076955</td>\n",
       "      <td>-0.138880</td>\n",
       "      <td>-0.079268</td>\n",
       "      <td>-0.244648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eight</th>\n",
       "      <td>-0.033224</td>\n",
       "      <td>0.192466</td>\n",
       "      <td>-0.507554</td>\n",
       "      <td>-0.419275</td>\n",
       "      <td>0.235861</td>\n",
       "      <td>0.105365</td>\n",
       "      <td>-0.255650</td>\n",
       "      <td>-0.200700</td>\n",
       "      <td>-0.053316</td>\n",
       "      <td>-0.733084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233600</td>\n",
       "      <td>-0.171980</td>\n",
       "      <td>0.286490</td>\n",
       "      <td>-0.620115</td>\n",
       "      <td>-0.104281</td>\n",
       "      <td>-0.584950</td>\n",
       "      <td>0.222393</td>\n",
       "      <td>0.159457</td>\n",
       "      <td>-0.355556</td>\n",
       "      <td>-0.570065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nine</th>\n",
       "      <td>0.105645</td>\n",
       "      <td>0.060501</td>\n",
       "      <td>-0.367164</td>\n",
       "      <td>-0.433360</td>\n",
       "      <td>0.425262</td>\n",
       "      <td>-0.032186</td>\n",
       "      <td>-0.136358</td>\n",
       "      <td>-0.358969</td>\n",
       "      <td>0.129830</td>\n",
       "      <td>-0.574778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081581</td>\n",
       "      <td>-0.280892</td>\n",
       "      <td>0.540993</td>\n",
       "      <td>-0.752147</td>\n",
       "      <td>-0.059858</td>\n",
       "      <td>-0.446215</td>\n",
       "      <td>0.033923</td>\n",
       "      <td>-0.036796</td>\n",
       "      <td>-0.296937</td>\n",
       "      <td>-0.314274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "zero   0.368413  0.714821 -0.532399 -0.153238 -0.184203  0.009934  0.028352   \n",
       "one    0.213226  0.484864 -0.032716 -0.026842  0.090642 -0.086201  0.195947   \n",
       "two   -0.121083  0.161060 -0.549375 -0.472711 -0.146909  0.155344 -0.133190   \n",
       "three  0.104971  0.313852 -0.340210 -0.434407 -0.049186  0.154321 -0.099751   \n",
       "four   0.039704  0.210273 -0.526674 -0.221241 -0.102211  0.203096 -0.147871   \n",
       "five  -0.039133  0.148628 -0.443105 -0.602812  0.024338 -0.077868 -0.239623   \n",
       "six    0.304316  0.202454 -0.506930 -0.336193  0.042346 -0.201237 -0.326339   \n",
       "seven  0.092242  0.176112 -0.475537 -0.412275  0.071916 -0.310987 -0.048490   \n",
       "eight -0.033224  0.192466 -0.507554 -0.419275  0.235861  0.105365 -0.255650   \n",
       "nine   0.105645  0.060501 -0.367164 -0.433360  0.425262 -0.032186 -0.136358   \n",
       "\n",
       "            7         8         9    ...       758       759       760  \\\n",
       "zero  -0.162773  0.163669 -0.471809  ...  0.637450 -0.782000  0.181008   \n",
       "one   -0.169620  0.540456 -0.261407  ...  0.455036 -0.426076  0.282586   \n",
       "two   -0.483241  0.173656 -0.328344  ...  0.303860  0.224042  0.113168   \n",
       "three -0.506876  0.389955 -0.244507  ...  0.379173  0.134788  0.233690   \n",
       "four  -0.331833  0.267574 -0.481170  ...  0.240441 -0.040645  0.122894   \n",
       "five  -0.467639  0.117604 -0.661229  ...  0.410685 -0.126665  0.254384   \n",
       "six   -0.235801  0.244673 -0.600611  ...  0.417288 -0.329488  0.127992   \n",
       "seven -0.409864  0.006404 -0.807861  ...  0.095583 -0.178779  0.421195   \n",
       "eight -0.200700 -0.053316 -0.733084  ...  0.233600 -0.171980  0.286490   \n",
       "nine  -0.358969  0.129830 -0.574778  ...  0.081581 -0.280892  0.540993   \n",
       "\n",
       "            761       762       763       764       765       766       767  \n",
       "zero  -1.160265  0.005396 -0.899586  0.350256 -0.099035 -0.274523  0.308869  \n",
       "one   -0.676856 -0.045337 -0.428130  0.227807  0.216206  0.112196 -0.128516  \n",
       "two   -0.807975 -0.281597 -0.575383  0.138091  0.198803 -0.091571 -0.442494  \n",
       "three -0.651362 -0.219017 -0.658988  0.203868  0.215337 -0.093137 -0.477617  \n",
       "four  -0.991067  0.013572 -0.848153  0.368776  0.249214 -0.265129 -0.095733  \n",
       "five  -0.834398 -0.037767 -0.695847  0.188720  0.237780 -0.017827 -0.366614  \n",
       "six   -0.932242 -0.041394 -0.668947 -0.093982  0.385106  0.048364 -0.338787  \n",
       "seven -0.693458  0.123755 -0.667253  0.076955 -0.138880 -0.079268 -0.244648  \n",
       "eight -0.620115 -0.104281 -0.584950  0.222393  0.159457 -0.355556 -0.570065  \n",
       "nine  -0.752147 -0.059858 -0.446215  0.033923 -0.036796 -0.296937 -0.314274  \n",
       "\n",
       "[10 rows x 768 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = 163\n",
    "num_inputs = 3\n",
    "num_layers = 2\n",
    "embed_dim = bert_embed.shape[1]\n",
    "freeze_embedding = True\n",
    "\n",
    "mod_bert_embed = TorchDeepNeuralClassifier(vals, output_size, num_inputs,\n",
    "                            num_layers, embed_dim, bert_embed,\n",
    "                            freeze_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished epoch 1000 of 1000; error is 0.04465832561254501"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TorchDeepNeuralClassifier(\n",
       "\tbatch_size=1028,\n",
       "\tmax_iter=1000,\n",
       "\teta=0.001,\n",
       "\toptimizer_class=<class 'torch.optim.adam.Adam'>,\n",
       "\tl2_strength=0,\n",
       "\tgradient_accumulation_steps=1,\n",
       "\tmax_grad_norm=None,\n",
       "\tvalidation_fraction=0.1,\n",
       "\tearly_stopping=False,\n",
       "\tn_iter_no_change=10,\n",
       "\twarm_start=False,\n",
       "\ttol=1e-05,\n",
       "\thidden_dim=50,\n",
       "\thidden_activation=Tanh(),\n",
       "\tnum_layers=2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_bert_embed.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.25      1.00      0.40         1\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       0.33      0.50      0.40         2\n",
      "           8       1.00      0.50      0.67         4\n",
      "          10       1.00      1.00      1.00         3\n",
      "          12       1.00      0.50      0.67         2\n",
      "          13       1.00      1.00      1.00         1\n",
      "          14       0.33      1.00      0.50         1\n",
      "          15       1.00      1.00      1.00         2\n",
      "          16       0.67      0.67      0.67         3\n",
      "          18       1.00      0.50      0.67         2\n",
      "          20       1.00      1.00      1.00         2\n",
      "          21       1.00      1.00      1.00         2\n",
      "          22       1.00      1.00      1.00         1\n",
      "          24       1.00      1.00      1.00         1\n",
      "          27       1.00      1.00      1.00         2\n",
      "          28       1.00      1.00      1.00         2\n",
      "          30       1.00      1.00      1.00         2\n",
      "          32       1.00      1.00      1.00         1\n",
      "          33       1.00      1.00      1.00         1\n",
      "          35       1.00      1.00      1.00         1\n",
      "          36       1.00      1.00      1.00         3\n",
      "          39       1.00      1.00      1.00         2\n",
      "          40       1.00      1.00      1.00         2\n",
      "          42       1.00      1.00      1.00         3\n",
      "          45       1.00      1.00      1.00         2\n",
      "          48       1.00      1.00      1.00         2\n",
      "          50       1.00      1.00      1.00         2\n",
      "          54       1.00      1.00      1.00         2\n",
      "          55       1.00      1.00      1.00         2\n",
      "          56       1.00      1.00      1.00         2\n",
      "          60       1.00      0.75      0.86         4\n",
      "          64       1.00      1.00      1.00         1\n",
      "          66       0.67      1.00      0.80         2\n",
      "          70       1.00      1.00      1.00         2\n",
      "          72       1.00      1.00      1.00         1\n",
      "          75       1.00      1.00      1.00         1\n",
      "          77       1.00      1.00      1.00         2\n",
      "          80       1.00      1.00      1.00         2\n",
      "          81       1.00      1.00      1.00         1\n",
      "          84       1.00      1.00      1.00         1\n",
      "          85       0.00      0.00      0.00         0\n",
      "          88       1.00      1.00      1.00         2\n",
      "          90       1.00      0.67      0.80         3\n",
      "          91       1.00      1.00      1.00         1\n",
      "          96       1.00      1.00      1.00         1\n",
      "         105       1.00      1.00      1.00         1\n",
      "         108       1.00      0.50      0.67         2\n",
      "         112       1.00      1.00      1.00         1\n",
      "         117       1.00      1.00      1.00         1\n",
      "         128       1.00      1.00      1.00         1\n",
      "         135       1.00      1.00      1.00         1\n",
      "         144       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.88       100\n",
      "   macro avg       0.88      0.87      0.86       100\n",
      "weighted avg       0.93      0.88      0.89       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jamesflemings/anaconda3/envs/nlu/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "preds = mod_bert_embed.predict(X_test)\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "23b0dade77de706664b673ec0b749cccbdb5cac5bb41527ce15ce25b9a737383"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('nlu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
